{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a81f166-5e99-4069-9814-e731f01ff950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea5d65b35a54cfdbf4eaf3bf6bff9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dea778-a343-4667-b891-9e96968380c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Generate Reasoning Steps from Context, Question, and Options\n",
    "def generate_reasoning_steps(context, question, options):\n",
    "    # Define the prompt for the first LLM instance to generate reasoning steps and premises\n",
    "    task_description = \"\"\"\n",
    "Task:\n",
    "You are a helpful legal assistant. Choose the correct option by performing legal reasoning while strictly adhering to the legal context below. \n",
    "The reasoning should start by generating the question-related premises first, which are the statements and relationships given in the Question and Legal Context. \n",
    "Then based on these, generate the reasoning process in steps. Each reasoning step should:\n",
    "1. Be logically consistent and based on the available premises.\n",
    "2. Cite the premises used to support each reasoning step in the format: {QC #}, where # refers to the premise number.\n",
    "3. Clearly explain how each step leads to the final answer.\n",
    "4. The reasoning steps should be in a sequential, deductive chain, with each step based only on the premises and steps generated previously.\n",
    "\n",
    "Please ensure that the output is clearly separated by special markers so that it can be parsed into individual elements later on.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Start with the Question-Context steps, followed by the Reasoning steps. Use the following structure:\n",
    "\n",
    "### Question-Context Steps:\n",
    "{QC 1} statement or relationship given/inferred in the Question and Legal Context.\n",
    "{QC 2} statement or relationship given/inferred in the Question and Legal Context.\n",
    "{QC 3} statement or relationship given/inferred in the Question and Legal Context.\n",
    "\n",
    "---\n",
    "\n",
    "### Reasoning Steps:\n",
    "Step 1: [Premise-based reasoning derived from {QC 1}, {QC 2}, etc.]\n",
    "Step 2: [Next reasoning step derived from previous steps and citing relevant premises]\n",
    "...\n",
    "Step N: [Final reasoning step and conclusion based on the chain of reasoning]\n",
    "\"\"\"\n",
    "\n",
    "    # Prepare the prompt\n",
    "    prompt = task_description + f\"\\nContext: {context}\\nQuestion: {question}\\nOptions: {options}\"\n",
    "\n",
    "    # Generate the reasoning steps\n",
    "    result = pipeline(prompt, max_length=4000, num_return_sequences=1)\n",
    "    reasoning_steps = result[0]['generated_text']\n",
    "    \n",
    "    # Parse the reasoning steps and question-context steps\n",
    "    question_context_steps = []\n",
    "    reasoning_step_list = []\n",
    "    \n",
    "    # Parsing the output\n",
    "    # Split based on the known markers to extract question-context and reasoning steps\n",
    "    question_context_marker = \"### Question-Context Steps:\"\n",
    "    reasoning_steps_marker = \"### Reasoning Steps:\"\n",
    "\n",
    "    # Extracting Question-Context Steps\n",
    "    question_context_section = reasoning_steps.split(question_context_marker)[2].split(reasoning_steps_marker)[0].strip()\n",
    "    for line in question_context_section.split(\"\\n\"):\n",
    "        if line.strip():\n",
    "            question_context_steps.append(line.strip())\n",
    "    \n",
    "    # Extracting Reasoning Steps\n",
    "    reasoning_steps_section = reasoning_steps.split(reasoning_steps_marker)[2].strip()\n",
    "    for line in reasoning_steps_section.split(\"\\n\"):\n",
    "        if line.strip():\n",
    "            reasoning_step_list.append(line.strip())\n",
    "    \n",
    "    preliminary_information = f\"\\nContext: {context}\\nQuestion: {question}\\nOptions: {options}\"\n",
    "    \n",
    "    return question_context_steps, reasoning_step_list, reasoning_steps, preliminary_information\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c2f643-00e9-441a-a4f0-3c0d3de024e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Validate Each Reasoning Step\n",
    "def validate_reasoning_step(question_context_steps, reasoning_steps, preliminary_information, step_number):\n",
    "    \"\"\"\n",
    "    # Extract the reasoning step number and cited premises\n",
    "    step_number = int(reasoning_step.split(\":\")[0].replace(\"Step\", \"\").strip())\n",
    "    reasoning_text = reasoning_step.split(\":\")[1].strip()\n",
    "    \n",
    "    # Get the premises for this reasoning step based on citations\n",
    "    premises_cited = []\n",
    "    for line in reasoning_step.split(\"Citations:\")[1:]:\n",
    "        cited_premises = line.strip().split(\",\")\n",
    "        premises_cited.extend([p.strip() for p in cited_premises])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the validation prompt using f-string and proper concatenation\n",
    "    validation_prompt = f\"\"\"\n",
    "Task:\n",
    "You are a legal expert. Validate the following reasoning step. Based on the given context, question, and options and other reasoning steps until then, determine if the reasoning step and its premises are logically sound and derivable from the provided information.\n",
    "\n",
    "{preliminary_information}\n",
    "\n",
    "### Question-Context Premises:\n",
    "{chr(10).join(question_context_steps)}\n",
    "\n",
    "### Previous Reasoning Premises: \n",
    "{chr(10).join(reasoning_steps[:step_number])}\n",
    "\n",
    "### Reasoning Step:\n",
    "{reasoning_steps[step_number]}\n",
    "\n",
    "Does this reasoning step follow logically from the context, question, options and other given premises information? Answer 'Yes' or 'No', and explain why.\n",
    "\"\"\"\n",
    "\n",
    "    # Validate the reasoning step\n",
    "    result = pipeline(validation_prompt, max_length=4000, num_return_sequences=1)\n",
    "    validation_output = result[0]['generated_text']\n",
    "    \n",
    "    # Check if the validation response is \"Yes\" or \"No\"\n",
    "    if \"Yes\" in validation_output:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6431dafb-b7de-4c50-bcc6-87d1cc15a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Process Dataset and Generate Prompts for Each Sample\n",
    "def process_sample(sample):\n",
    "    context = sample['context']\n",
    "    question = sample['question']\n",
    "    options = sample['options']\n",
    "\n",
    "    # Generate reasoning steps for this sample\n",
    "    question_context_steps, reasoning_steps, generated_text, preliminary_information = generate_reasoning_steps(context, question, options)\n",
    "\n",
    "    # Validate each reasoning step sequentially\n",
    "    reasoning_validations = []\n",
    "    for step_number in range(len(reasoning_steps)):\n",
    "        # Validate this reasoning step\n",
    "        is_valid = validate_reasoning_step(question_context_steps, reasoning_steps, preliminary_information, step_number)\n",
    "        reasoning_validations.append(is_valid)\n",
    "\n",
    "    return reasoning_validations, reasoning_steps, generated_text, question_context_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959578ef-f695-4a43-a9e7-b8faf3a601cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function to load data, process and validate reasoning steps for all samples\n",
    "def main():\n",
    "    # Load the JSON dataset\n",
    "    with open('legal_reasoning_30_sample.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Process each sample and validate reasoning steps\n",
    "    for sample in data['legal_scenarios']:\n",
    "        reasoning_validations, reasoning_steps, generated_text, question_context_steps = process_sample(sample)\n",
    "\n",
    "        # Add the generated data to the sample\n",
    "        sample['reasoning_validations'] = reasoning_validations\n",
    "        sample['reasoning_steps'] = reasoning_steps\n",
    "        sample['generated_text'] = generated_text\n",
    "        sample['question_context_steps'] = question_context_steps\n",
    "\n",
    "    # Save the updated data into a new JSON file\n",
    "    with open('processed_legal_reasoning_samples.json', 'w') as output_file:\n",
    "        json.dump(data, output_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
